{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Learning\n",
        "Use the order of operations:\n",
        "1. Remove stop words\n",
        "2. Stemming\n",
        "3. Bag of Wordds\n",
        "\n## Bag of Words"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "emails = [\n",
        "    \"hi Katie the self driving car will be late Best Sebastian\",\n",
        "    \"Hi Sebastian the machine learning class will be great great great Best Katie\",\n",
        "    \"Hi Katie the maching learning class will be most Rexcellent\"]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(emails)\n",
        "bag_of_words = vectorizer.transform(emails)\n",
        "# print(bag_of_words)\n",
        "vectorizer.vocabulary_.get(\"great\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words\n",
        "Words that provide little information and are typically removed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "len(sw)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Stemming\n",
        "Find the stem of similar words."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "print(stemmer.stem('responsiveness'))\n",
        "print(stemmer.stem('responsivity'))\n",
        "print(stemmer.stem('unresponsive'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "respons\n",
            "respons\n",
            "unrespons\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TfIdf Representation\n",
        "* Tf = term frequency (like bag of words)\n",
        "* Idf = inverse document frequency (weight by how often word occurs in corpus)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}